{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7838ce",
   "metadata": {},
   "source": [
    "# 2021-09-03\n",
    "\n",
    "Trying to work out if we can deduce meltpool size, orientation, dimensions, from the images a bit better than just a size readout\n",
    "\n",
    "Could be used to search for anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98254585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib # Used during testing if I need to reload modules\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776fb271",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import ngif_romar.tools\n",
    "except ModuleNotFoundError as error:\n",
    "    # If not in path/installed, use relative import\n",
    "    module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "    sys.path.append(module_path)\n",
    "    import ngif_romar.tools as tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d9cecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data.dat', 'Frames', 'SN2_Run1_Time_Data.txt']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(\"..\", \"data\", \"SN2\", \"20200930_1500_\")\n",
    "logfile_path = os.path.join(dataset_path, \"Data.dat\")\n",
    "meta_dict, data_df = tools.read_data(logfile_path)\n",
    "\n",
    "data_df = tools.post_process_log_data(data_df)\n",
    "data_df.head()\n",
    "\n",
    "print(os.listdir(dataset_path))\n",
    "frames_path = os.path.join(dataset_path, \"Frames\")\n",
    "\n",
    "data_df = tools.link_camera_frames_to_df(data_df, frame_folder_path=frames_path)\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e4bf9",
   "metadata": {},
   "source": [
    "Lets have a look at some images, and try to thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data_df[\n",
    "    data_df[\"toolpath_key\"] == 15\n",
    "]\n",
    "framename = subset[\"matching_frame_filename\"].values[5]\n",
    "frame = tools.read_and_convert_image(os.path.join(frames_path, framename))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(frame, cmap='gray', vmin=0, vmax=255)\n",
    "fig.colorbar(imshow_result)\n",
    "plt.show()\n",
    "\n",
    "# Plot without cmap to see if it's easier to see\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(frame,  vmin=0, vmax=255)\n",
    "fig.colorbar(imshow_result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "otsu_thresh_val, thresh_img = cv2.threshold(frame, 128, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "print(\"Otsu thresh: value is {}\".format(otsu_thresh_val))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(thresh_img, cmap='gray', vmin=0, vmax=255)\n",
    "fig.colorbar(imshow_result)\n",
    "ax.set_title(\"Otsu thresh\")\n",
    "plt.show()\n",
    "\n",
    "manual_thresh = 19\n",
    "manual_thresh, thresh_img = cv2.threshold(frame, manual_thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(thresh_img, cmap='gray', vmin=0, vmax=255)\n",
    "fig.colorbar(imshow_result)\n",
    "ax.set_title(\"Manual Thresh\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(frame.flatten(), bins=np.arange(-0.5, 256, 1))\n",
    "ax.set_title(\"Histogram of picture intensiteis\")\n",
    "ax.axvline(otsu_thresh_val, linestyle=\"--\", label=\"Otsu thresh\")\n",
    "ax.axvline(manual_thresh, linestyle=\"-.\", label=\"Manual thresh {}\".format(manual_thresh))\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets mask off areas \n",
    "\n",
    "display_img = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "regions = [\n",
    "    [0, 19],\n",
    "    [19,50],\n",
    "    [50, 100],\n",
    "    [100, 256]\n",
    "]\n",
    "colours = [\n",
    "    [0,0,0],\n",
    "    [0,255,0],\n",
    "    [0,0,255],\n",
    "    [255,0,255],\n",
    "]\n",
    "for (low, high), colour in zip(regions, colours):\n",
    "    display_img[\n",
    "        (frame >= low)\n",
    "        & (frame < high)\n",
    "    ] = colour\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(display_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83366a",
   "metadata": {},
   "source": [
    "As sort of said before, Otsu thresh is a good auto estimate, but we should look at the off frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d947b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "off_frames = data_df[\n",
    "    data_df[\"laser_off_time(ms)\"] > 100\n",
    "][\"matching_frame_filename\"].values\n",
    "\n",
    "framename = off_frames[30]\n",
    "frame = tools.read_and_convert_image(os.path.join(frames_path, framename))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(frame, cmap='gray', vmin=0, vmax=255)\n",
    "fig.colorbar(imshow_result)\n",
    "ax.set_title(\"Frame as read in\")\n",
    "plt.show()\n",
    "\n",
    "otsu_thresh_val, thresh_img = cv2.threshold(frame, 128, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "print(\"Otsu thresh: value is {}\".format(otsu_thresh_val))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(thresh_img, cmap='gray', vmin=0, vmax=255)\n",
    "fig.colorbar(imshow_result)\n",
    "ax.set_title(\"Otsu thresh\")\n",
    "plt.show()\n",
    "\n",
    "manual_thresh = 9\n",
    "manual_thresh, thresh_img = cv2.threshold(frame, manual_thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(thresh_img, cmap='gray', vmin=0, vmax=255)\n",
    "fig.colorbar(imshow_result)\n",
    "ax.set_title(\"Manual Thresh\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(frame.flatten(), bins=np.arange(0,256, 1))\n",
    "ax.set_title(\"Histogram of picture intensiteis\")\n",
    "ax.axvline(otsu_thresh_val, linestyle=\"--\", label=\"Otsu thresh\")\n",
    "ax.axvline(manual_thresh, linestyle=\"-.\", label=\"Manual thresh {}\".format(manual_thresh))\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ab060",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(frame.flatten(), bins=np.arange(-0.5,np.max(frame)+1, 1))\n",
    "ax.set_title(\"Histogram of picture intensiteis\")\n",
    "ax.axvline(otsu_thresh_val, linestyle=\"--\", label=\"Otsu thresh {}\".format(otsu_thresh_val))\n",
    "ax.axvline(manual_thresh, linestyle=\"-.\", label=\"Manual thresh {}\".format(manual_thresh))\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e325970d",
   "metadata": {},
   "source": [
    "Okay, looking at one or two individual frames, looking at vals > 0 is pretty good when the laser is off\n",
    "\n",
    "We still need to figure out what's going on with the multiple peaks in the laser on frames but still\n",
    "\n",
    "Looks like we could separate into four regions? Cold, leading edge, building area, and transition area\n",
    "\n",
    "* Leading edge/laser area: Where the laser has just hit and the pool hasn't liquified or isn't being cooled by particles\n",
    "* Building area: Pool hot/liquid, powder flowing in, building\n",
    "* Transition area: between building and cold, where the laser has just started or where it's left and cooling down\n",
    "* Cold: The cold areas, not necessarily as dark as the laser off images due to reflections etc\n",
    "\n",
    "Also not that we can see the edge of the nozzle or something in the corner\n",
    "\n",
    "Try k means clustering b/c why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe6a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cae7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.cluster.vq.kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data_df[\n",
    "    data_df[\"toolpath_key\"] == 15\n",
    "]\n",
    "framename = subset[\"matching_frame_filename\"].values[5]\n",
    "frame = tools.read_and_convert_image(os.path.join(frames_path, framename))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(frame, cmap='gray', vmin=0, vmax=255)\n",
    "fig.colorbar(imshow_result)\n",
    "plt.show()\n",
    "\n",
    "# Plot without cmap to see if it's easier to see\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(frame,  vmin=0, vmax=255)\n",
    "fig.colorbar(imshow_result)\n",
    "plt.show()\n",
    "\n",
    "scipy.cluster.vq.kmeans(frame.astype(float).flatten(), 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92eacd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, distortion = scipy.cluster.vq.kmeans(frame.astype(float).flatten(), 1)\n",
    "print(\"Means: {}, distortion: {}\".format(means, distortion))\n",
    "# As a sanity check, k means with one mean should be the global mean\n",
    "print(np.mean(frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a099f81",
   "metadata": {},
   "source": [
    "Distortion is mean Euclidean distance between observations as entered and their centroids\n",
    "\n",
    "Basically, lower means points close to value\n",
    "\n",
    "See https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.kmeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de921b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "ks = np.arange(2, 10, 1)\n",
    "for k in ks:\n",
    "    means, distortion = scipy.cluster.vq.kmeans(frame.astype(float).flatten(), k)\n",
    "    distortions.append(distortion)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(ks, distortions)\n",
    "ax.set_xlabel(\"K (number means)\")\n",
    "ax.set_ylabel(\"Distortion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f637542",
   "metadata": {},
   "source": [
    "Turns around 5 or 6 means, which we sort of saw before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13655c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, distortion = scipy.cluster.vq.kmeans(frame.astype(float).flatten(), 4)\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data_df[\n",
    "    data_df['laser_on_time(ms)'] > 100\n",
    "]\n",
    "framename = subset[\"matching_frame_filename\"].values[275]\n",
    "frame = tools.read_and_convert_image(os.path.join(frames_path, framename))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(frame, cmap='gray', vmin=0, vmax=255)\n",
    "fig.colorbar(imshow_result)\n",
    "plt.show()\n",
    "\n",
    "# Plot without cmap to see if it's easier to see\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(frame,  vmin=0, vmax=255)\n",
    "fig.colorbar(imshow_result)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, distortion = scipy.cluster.vq.kmeans(frame.astype(float).flatten(), 4)\n",
    "means, distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, distortion = scipy.cluster.vq.kmeans(frame.astype(float).flatten(), 4)\n",
    "means, distortion\n",
    "\n",
    "display_img = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "means = np.sort(means)\n",
    "colours = [\n",
    "    [0,0,0],\n",
    "    [255,0,0],\n",
    "    [0,255,0],\n",
    "    [0,0,255],\n",
    "    [255,0,255],\n",
    "    [0, 255, 255],\n",
    "]\n",
    "\n",
    "for i in range(0, frame.shape[0]):\n",
    "    for j in range(0, frame.shape[1]):\n",
    "        display_img[i,j] = colours[np.argmin(np.abs(means - frame[i,j]))]\n",
    "        \n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(display_img)\n",
    "plt.show()\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de683b",
   "metadata": {},
   "source": [
    "Going by the above on a couple of images, I don't think I'm fair off with my 4 region idea\n",
    "\n",
    "If we just look at the onnish ones, its a thresh of mean_1 + (mean_2 - mean_1)/2 ~ whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ca75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_val = means[0] + (means[0] + means[1]) / 2\n",
    "print(thresh_val)\n",
    "# thresh_val=29\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(frame.flatten(), bins=np.arange(-0.5, 256, 1))\n",
    "ax.axvline(thresh_val, linestyle=\"--\")\n",
    "plt.show()\n",
    "\n",
    "thresh_val, thresh_img = cv2.threshold(frame, thresh_val, 255, cv2.THRESH_BINARY)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(thresh_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ff4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets go through and sample a bunch of images, and check histo\n",
    "\n",
    "subset = data_df[\n",
    "    data_df['laser_on_time(ms)'] > 100\n",
    "]\n",
    "framenames = subset[\"matching_frame_filename\"]\n",
    "print(\"Total number of frames to select: {}\".format(len(framenames)))\n",
    "sample_size = 150\n",
    "sample_framenames = np.random.choice(framenames, sample_size, replace=False)\n",
    "all_pixels = []\n",
    "for framename in sample_framenames:\n",
    "    frame = tools.read_and_convert_image(os.path.join(frames_path, framename))\n",
    "    all_pixels = np.concatenate([all_pixels, frame.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9155cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(all_pixels, bins=np.arange(-0.5, 256, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644c3440",
   "metadata": {},
   "source": [
    "Still need to figure out a consistent but per image threshold, and then we can look at the orientation and directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a655a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pass, just do the Otsu thresh, even if we have problems with it\n",
    "\n",
    "thresh_val, thresh_img = cv2.threshold(frame, 40, 255, cv2.THRESH_BINARY)\n",
    "print(thresh_val)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(frame.flatten(), bins=np.arange(-0.5, 256, 1))\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(thresh_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to threshed image and do connected components, find largest\n",
    "retval, labels, stats, centroid = cv2.connectedComponentsWithStats(thresh_img)\n",
    "# Stats is an array, row for each connected component, stats are tl x, tl y, bbox width, bbox height, area\n",
    "\n",
    "display_img = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "for label in range(0, retval):\n",
    "    display_img[labels==label] = np.random.randint(0,256, size=3)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(display_img)\n",
    "plt.show()\n",
    "\n",
    "display_img = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "display_img = display_img * 0\n",
    "max_size_label = np.argmax(stats[1:,4]) +1 # Plus one because we offset the array to not inc background\n",
    "display_img[labels == max_size_label] = [255,255,255]\n",
    "\n",
    "# Print just the largest\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(display_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e3410",
   "metadata": {},
   "source": [
    "## So far:\n",
    "\n",
    "What we've done is have a look at putting into three groups via knn method. It seems to line up with the basic idea of roughly four temperature levels\n",
    "\n",
    "We also had a quick look at the Otsu thresh; it's not perfect, but works sometimes. With that we can get a different blob.\n",
    "\n",
    "## Next:\n",
    "\n",
    "Lets form a method that can measure the dimensions of the shape\n",
    "\n",
    "The camera should be calibrated against a curve, so we should be able to set the threshold as a set temp. We can always refine this. In previous sections we combined multiple images to try and see if there were clear peaks\n",
    "\n",
    "Note that for the moment we're mainly concerned with width\n",
    "\n",
    "### Ideas:\n",
    "* Look at the outer regions of the image; we know that this area should be cold and empty so we can use that as a thresh\n",
    "* See if we can consistently find the orientation of the image, then align to that and do row and col scans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf5da4",
   "metadata": {},
   "source": [
    "### Using background to find thresh\n",
    "\n",
    "Open a bunch of images, mask out centre, use that to find background level of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data_df[\n",
    "    data_df['laser_on_time(ms)'] > 100\n",
    "]\n",
    "framenames = subset[\"matching_frame_filename\"]\n",
    "print(\"Total number of frames to select: {}\".format(len(framenames)))\n",
    "\n",
    "# Choosing arb image\n",
    "framename = framenames[100]\n",
    "\n",
    "frame = tools.read_and_convert_image(os.path.join(frames_path, framename))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(frame)\n",
    "fig.colorbar(imshow_result)\n",
    "plt.show()\n",
    "\n",
    "# Create a mask\n",
    "ii, jj = np.indices(frame.shape)\n",
    "# Centring coords\n",
    "ii = ii - frame.shape[0]//2\n",
    "jj = jj - frame.shape[1]//2\n",
    "# Will be used for mask; at the moment an array of distance from centre\n",
    "distances = np.linalg.norm([ii,jj], axis=0)\n",
    "mask = np.zeros_like(frame)\n",
    "mask[\n",
    "    (distances > 55)\n",
    "    & (distances < 105)\n",
    "    & (ii < 0) #Getting upper part, chosen image has a tail\n",
    "] = 1\n",
    "\n",
    "masked_in = frame*mask\n",
    "masked_out = frame*(~mask//255)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(mask, cmap='gray')\n",
    "fig.colorbar(imshow_result)\n",
    "ax.set_title(\"Proposed mask\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(~mask, cmap='gray')\n",
    "fig.colorbar(imshow_result)\n",
    "ax.set_title(\"Inv. of mask\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(masked_in)\n",
    "fig.colorbar(imshow_result)\n",
    "ax.set_title(\"Masked in\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(masked_out)\n",
    "fig.colorbar(imshow_result)\n",
    "ax.set_title(\"Masked out\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0364caa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a730215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not including the zero parts buecause it blows out the scale\n",
    "fig, ax = plt.subplots()\n",
    "bins = np.arange(0.5, 20, 1)\n",
    "ax.hist(masked_in.flatten(), bins=bins, density=True)\n",
    "xs = np.linspace(0, 20, 100)\n",
    "ax.plot(xs+2.1, scipy.stats.gamma.pdf(xs, 4))\n",
    "# Putting in gamma distro for comp.\n",
    "ax.set_title(\"Masked in; dark parts\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Masked in: mean {:.3g}, std {:.3g}, sqrt(mean) {:.3g}\".format(\n",
    "    np.mean(masked_in), np.std(masked_in), np.sqrt(np.mean(masked_in))\n",
    "))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(masked_out.flatten(), bins=np.arange(0.5, 256, 1))\n",
    "ax.set_title(\"Masked out; outer parts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ffaa0",
   "metadata": {},
   "source": [
    "The outer parts look kind of poissonian/gamma distro, which is interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724153a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subset = data_df[\n",
    "    data_df['laser_on_time(ms)'] > 100\n",
    "]\n",
    "framenames = subset[\"matching_frame_filename\"]\n",
    "print(\"Total number of frames to select: {}\".format(len(framenames)))\n",
    "\n",
    "# Choosing arb image\n",
    "framename = framenames[9000]\n",
    "\n",
    "frame = tools.read_and_convert_image(os.path.join(frames_path, framename))\n",
    "\n",
    "thresh_val = 20\n",
    "thresh_val, thresh_img = cv2.threshold(frame, thresh_val, 255, cv2.THRESH_BINARY)\n",
    "# thresh_val, thresh_img = cv2.threshold(frame, 40, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "print(thresh_val)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(frame)\n",
    "fig.colorbar(imshow_result)\n",
    "ax.set_title(\"Input image\")\n",
    "plt.show()\n",
    "\n",
    "# Look at rows, roughly centre +/- a bit\n",
    "row_nums = [\n",
    "    80, 60, 100\n",
    "]\n",
    "fig, ax = plt.subplots()\n",
    "for i in row_nums:\n",
    "    ax.plot(frame[i, :], label=\"Row {}\".format(i))\n",
    "ax.legend()\n",
    "ax.set_title(\"Row scan of pixel values\")\n",
    "plt.show()\n",
    "\n",
    "# Look at cols as well\n",
    "col_nums = [\n",
    "    150, 120, 90\n",
    "]\n",
    "fig, ax = plt.subplots()\n",
    "for j in col_nums:\n",
    "    ax.plot(frame[:, j], label=\"Col {}\".format(j))\n",
    "ax.legend()\n",
    "ax.set_title(\"Column scan of pixel values\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(frame.flatten(), bins=np.arange(-0.5, 256, 1))\n",
    "ax.axvline(thresh_val)\n",
    "ax.set_title(\"Histogram of image valuse\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(thresh_img, cmap='gray')\n",
    "ax.set_title(\"Threshed image\")\n",
    "plt.show()\n",
    "\n",
    "retval, labels, stats, centroid = cv2.connectedComponentsWithStats(thresh_img)\n",
    "# Stats is an array, row for each connected component, stats are tl x, tl y, bbox width, bbox height, area\n",
    "\n",
    "display_img = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "for label in range(0, retval):\n",
    "    display_img[labels==label] = np.random.randint(0,256, size=3)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(display_img)\n",
    "plt.show()\n",
    "\n",
    "display_img = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "display_img = display_img * 0\n",
    "max_size_label = np.argmax(stats[1:,4]) +1 # Plus one because we offset the array to not inc background\n",
    "display_img[labels == max_size_label] = [255,255,255]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Now lets grab a uint8 image to work on further\n",
    "proc_image = np.zeros_like(thresh_img)\n",
    "proc_image[labels == max_size_label] = 255\n",
    "\n",
    "\n",
    "# Do a close to kill islands\n",
    "# Do a morpho close transform\n",
    "kernel = np.ones((10,10), np.uint8)\n",
    "proc_image = cv2.morphologyEx(proc_image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(proc_image, cmap='gray')\n",
    "fig.colorbar(imshow_result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799fa5dd",
   "metadata": {},
   "source": [
    "Now we've processed the image etc we have a blob to work with\n",
    "\n",
    "We want to fit a vague ellipse, and measure dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07bf9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(proc_image, 100, 100,)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_result = ax.imshow(edges, cmap='gray')\n",
    "fig.colorbar(imshow_result)\n",
    "plt.show()\n",
    "\n",
    "# Draw the edges onto the original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a4eda",
   "metadata": {},
   "source": [
    "Use that old PCA method I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c18c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii, jj = np.indices(proc_image.shape)\n",
    "ii = ii[proc_image > 0] \n",
    "jj = jj[proc_image > 0]\n",
    "\n",
    "coords = np.vstack([ii, jj]).transpose()\n",
    "# Now have an array of (i,j) correspond to the blob\n",
    "\n",
    "# PCA: now centre at mean\n",
    "coords = coords - np.mean(coords)\n",
    "# Covariance matrix\n",
    "\n",
    "# Remember that diagonals are variance of values\n",
    "cov_mat = np.cov(coords, rowvar=False)\n",
    "# Then if we diag the covariance matrix we should get an estimate of extent and orientation from eigenvectors\n",
    "eig_vals, eig_vectors = np.linalg.eig(cov_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = -1 * np.arctan2(eig_vectors[1,0], eig_vectors[0,0]) # align to have first eig vector on X axis\n",
    "\n",
    "rot_mat = np.array([\n",
    "    [np.cos(angle), -np.sin(angle)],\n",
    "    [np.sin(angle), np.cos(angle)],\n",
    "])\n",
    "\n",
    "rot_mat @ eig_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31041cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now rotate all coords, and then our eigenvectors corresp. to highest variance will be aligned\n",
    "\n",
    "rot_coords = np.array([rot_mat @ coord for coord in coords])\n",
    "rot_cov = np.cov(rot_coords, rowvar=False)\n",
    "np.sqrt(rot_cov[0,0]), np.sqrt(rot_cov[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab8a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at rotated image\n",
    "\n",
    "centre =  (frame.shape[0]//2, frame.shape[1]//2)\n",
    "transform_mat = cv2.getRotationMatrix2D(centre, angle, 1)\n",
    "\n",
    "rot_image = cv2.warpAffine(frame, transform_mat, frame.shape[::-1])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(rot_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3de272",
   "metadata": {},
   "source": [
    "So, we can use a PCA type method to find the orientation and rotate to that. Image rotation might not be that helpful, but still"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47faa1bd",
   "metadata": {},
   "source": [
    "## Another idea: Line scan from middle of image\n",
    "\n",
    "We know that the middle of the image should be roughly coincident with the laser, so let's scan in lines around that, and check width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_pixels_along_line(x0, y0, x1, y1):\n",
    "    \"\"\"\n",
    "    From https://stackoverflow.com/questions/24702868/python3-pillow-get-all-pixels-on-a-line\n",
    "    Not ideal at the moment, need to make check that we're getting appropriate samples along lines but still\n",
    "    \n",
    "    Uses Xiaolin Wu's line algorithm to interpolate all of the pixels along a\n",
    "    straight line, given two points (x0, y0) and (x1, y1)\n",
    "\n",
    "    Wikipedia article containing pseudo code that function was based off of:\n",
    "        http://en.wikipedia.org/wiki/Xiaolin_Wu's_line_algorithm\n",
    "    \"\"\"\n",
    "    pixels = []\n",
    "    steep = abs(y1 - y0) > abs(x1 - x0)\n",
    "\n",
    "    # Ensure that the path to be interpolated is shallow and from left to right\n",
    "    if steep:\n",
    "        t = x0\n",
    "        x0 = y0\n",
    "        y0 = t\n",
    "\n",
    "        t = x1\n",
    "        x1 = y1\n",
    "        y1 = t\n",
    "\n",
    "    if x0 > x1:\n",
    "        t = x0\n",
    "        x0 = x1\n",
    "        x1 = t\n",
    "\n",
    "        t = y0\n",
    "        y0 = y1\n",
    "        y1 = t\n",
    "\n",
    "    dx = x1 - x0\n",
    "    dy = y1 - y0\n",
    "    gradient = dy / dx  # slope\n",
    "\n",
    "    # Get the first given coordinate and add it to the return list\n",
    "    x_end = round(x0)\n",
    "    y_end = y0 + (gradient * (x_end - x0))\n",
    "    xpxl0 = x_end\n",
    "    ypxl0 = round(y_end)\n",
    "    if steep:\n",
    "        pixels.extend([(ypxl0, xpxl0), (ypxl0 + 1, xpxl0)])\n",
    "    else:\n",
    "        pixels.extend([(xpxl0, ypxl0), (xpxl0, ypxl0 + 1)])\n",
    "\n",
    "    interpolated_y = y_end + gradient\n",
    "\n",
    "    # Get the second given coordinate to give the main loop a range\n",
    "    x_end = round(x1)\n",
    "    y_end = y1 + (gradient * (x_end - x1))\n",
    "    xpxl1 = x_end\n",
    "    ypxl1 = round(y_end)\n",
    "\n",
    "    # Loop between the first x coordinate and the second x coordinate, interpolating the y coordinates\n",
    "    for x in range(xpxl0 + 1, xpxl1):\n",
    "        if steep:\n",
    "            pixels.extend([(np.floor(interpolated_y), x), (np.floor(interpolated_y) + 1, x)])\n",
    "\n",
    "        else:\n",
    "            pixels.extend([(x, np.floor(interpolated_y)), (x, np.floor(interpolated_y) + 1)])\n",
    "\n",
    "        interpolated_y += gradient\n",
    "\n",
    "    # Add the second given coordinate to the given list\n",
    "    if steep:\n",
    "        pixels.extend([(ypxl1, xpxl1), (ypxl1 + 1, xpxl1)])\n",
    "    else:\n",
    "        pixels.extend([(xpxl1, ypxl1), (xpxl1, ypxl1 + 1)])\n",
    "\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ce866",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "angles = np.linspace(-np.pi/2, np.pi/2, 10)\n",
    "angles = angles[:-1]\n",
    "\n",
    "centre = np.array([frame.shape[0]//2, frame.shape[1]//2])\n",
    "max_dim = 256\n",
    "\n",
    "pixel_values = []\n",
    "\n",
    "for angle in angles:\n",
    "    # Start, end in i,j\n",
    "    start = centre - max_dim * np.array([np.sin(angle), np.cos(angle)])\n",
    "    end = centre + max_dim * np.array([np.sin(angle), np.cos(angle)])\n",
    "    start = start.astype(int)\n",
    "    end = end.astype(int)\n",
    "    # Line drawing takes xy\n",
    "    cv2.line(display_image, tuple(start[::-1]), tuple(end[::-1]), (255,0,0), 1)\n",
    "    \n",
    "    # Now try and get pixel values\n",
    "    indices = np.array(interpolate_pixels_along_line(*start, *end))\n",
    "    # Ensure we only get pts inside image\n",
    "    indices = indices[\n",
    "        (indices[:,0] >= 0)\n",
    "        & (indices[:, 1] >= 0)\n",
    "        & (indices[:, 0] < frame.shape[0])\n",
    "        & (indices[:,1] < frame.shape[1])\n",
    "    ]\n",
    "    # Round\n",
    "    indices = np.round(indices).astype(int)\n",
    "    these_pixel_values = frame[indices[:,0], indices[:,1]]\n",
    "    pixel_values.append(these_pixel_values)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(display_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for line_sample, angle in zip(pixel_values, angles):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(line_sample)\n",
    "    ax.set_title(\"Angle: {}/{}\".format(angle, np.degrees(angle)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9234e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce38233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ab41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac959aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb4348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1dbb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eca2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2529d7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bad565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
